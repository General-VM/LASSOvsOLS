---
title: "LASSO vs OLS"
author: "Victor Matyiku, Rebecca Ly"
date: "2025-03-06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# P = 10

## Set up

```{r}
p <- 10
n <- 100

beta0 <- rnorm(1)
#beta <- matrix(rnorm(p), nrow = p, ncol = 1)
beta <- c(1, 2, 3, 0, 5, 6, 0, 8, 0, 0) 

predictors <- matrix(
  rnorm(n*p), nrow = n, ncol = p,
  dimnames = list(rows = 1:n, cols = paste("X", 1:p, sep=""))
)

errors <- rnorm(n)
observations <- data.frame(Y = beta0 + predictors %*% beta + errors)

generated_data <- as.data.frame(
  cbind(observations, predictors)
)
head(generated_data)
```

## OLS

```{r}
ols_model <- lm(Y ~ ., generated_data)
significant_coefs <- data.frame(Value = summary(ols_model)$coef[summary(ols_model)$coef[,4] <= .05, 4])
significant_coefs
```

```{r}
if (is.na(significant_coefs["(Intercept)",])) {
  ols_beta_0 <- 0
  ols_coefs <- significant_coefs
} else {
  ols_beta_0 <- significant_coefs["(Intercept)",]
}

ols_coefs <- significant_coefs[row.names(significant_coefs) != "(Intercept)", , drop = FALSE]
ols_coefs
```

```{r}
res <- data.frame(Residuals = observations$Y - ols_beta_0 - predictors[, row.names(ols_coefs)] %*% ols_coefs$Value)
sq_error <- (norm(as.matrix(res, ncol=1), "e"))^2
sq_error
```

```{r}
q <- length(ols_coefs$Value)
q
```

## LASSO

```{r}
library(glmnet)
q_prime_lasso <- matrix(0, 100, 1) #list of q' for lasso

#generating data
X <- predictors
Y <- as.matrix(observations, nrow = n)

# LASSO with CV
cv.fit <- cv.glmnet(X, Y, nfolds=10, family="gaussian") 

# optimal lambda
selected_lambda <- cv.fit$lambda.min 

# coefficients for LASSO model using selected_lambda
lasso_coefs = coef(cv.fit, s="lambda.min") 

#predict new coefficients using LASSO & selected_lambda
prediction <- predict(cv.fit, type="coefficients", s=selected_lambda)  

squared_error <- sum((lasso_coefs-prediction)^2)

# finding number of predictors chosen by LASSO
q_prime <- length(which(prediction!=0))

q_prime_lasso[i] <- q_prime

summary(q_prime_lasso)
```